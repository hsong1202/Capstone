{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brainstorming\n",
    "\n",
    "Create a definition statement / question for your DAP Capstone example:\tI want to build a data analysis that answers the following question about (insert some or other subject here): \n",
    "\n",
    "\tI want to perform data analysis on change in housing prices in Washoe County and factors that contribut to the price fluctutation\n",
    "\n",
    "My questions are\n",
    "\n",
    "\twhat is the average price of the house sold for the zipcode?\n",
    "\n",
    "\twhat is the median price of the house sold for the zipcode?\n",
    "\n",
    "\twhat is the national average of a similar property sold?\n",
    "\n",
    "\tWhat is the national median price of a similar property sold?\n",
    "\n",
    "\twhat is the average income of the families living in that area?\n",
    "\n",
    "\twhat is the median income of the families living in that area?\n",
    "\n",
    "\tWhat factors contributed to the change in housing price?\n",
    "\n",
    "\twhat defines a single house home\n",
    "\n",
    "a Definition of the Audience / type of personas that might be interested in this analysis\t\n",
    "\n",
    "\tBuyer - a person interested in buying a house\n",
    "\n",
    "\tSeller - a person interested in selling their house\n",
    "\n",
    "\tLocal government - public entity interested in developing in a new area\n",
    "\n",
    "\tBusinesses - private entity interested in investing in a new area\n",
    "\n",
    "What datasets do I need to help me answer the above question for my particular audience?\t\n",
    "\t\n",
    "\twhat zipcodes include Washoe county?\n",
    "\t\n",
    "\thow many rooms are in a house?\n",
    "\t\n",
    "\thow big is the property?\n",
    "\t\n",
    "\twhat year was it built?\n",
    "\t\n",
    "\twhat are the historical prices of the property sold\n",
    "\t\n",
    "\tWhat was the Federal Reserve's interest rate during the year that it was sold?\n",
    "\t\n",
    "\n",
    "Choose any publicly Internet-available dataset(s)\t\n",
    "\t\n",
    "\n",
    "What research do I need to do to find data sources for my Capstone?\t\n",
    "\t\n",
    "\n",
    "List resources researched: (links to websites / materials)\t\n",
    "\t\n",
    "\n",
    "Note what you like about each resource and why you chose it\t\n",
    "\t\n",
    "\n",
    "Name other reference sources you want to consult\t\n",
    "\t\n",
    "\tWashoecounty.gov\n",
    "\t\n",
    "\tFederalreserve.gov\n",
    "\t\n",
    "\tData.gov\n",
    "\t\n",
    "\thousing.nv.gov\n",
    "\t\n",
    "\tCensus.gov\n",
    "\t\n",
    "\twww.nar.realtor\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Development\n",
    "\n",
    "1.\n",
    "\n",
    "Topic:\n",
    "\n",
    "    Is the price of single-family homes in Reno too high? \n",
    "\n",
    "Context:\n",
    "\n",
    "    The single-family home prices in the United States have soared over the years and although there have been some improvements in the affordability of single-family homes, I wanted to see how much the price of single-family homes has changed over time in Reno. \n",
    "\n",
    "2.\n",
    "\n",
    "Datasets:\n",
    "\n",
    "“Primary” dataset:\n",
    "\n",
    "    https://www.washoecounty.gov/assessor/online_data/sales_reports.php\n",
    "\n",
    "\n",
    "report for homes from 2005 to 2022\n",
    "\n",
    "    QISales2005.csv,\n",
    "\n",
    "    QISales2006.csv,\n",
    "\n",
    "    QISales2007.csv,\n",
    "\n",
    "    QISales2008.csv,\n",
    "\n",
    "    QISales2009.csv,\n",
    "\n",
    "    QISales2010.csv,\n",
    "\n",
    "    QISales2011.csv,\n",
    "\n",
    "    QISales2012.csv,\n",
    "\n",
    "    RDEQISales2013.csv,\n",
    "\n",
    "    RDEQISales2014.csv,\n",
    "\n",
    "    RDEQISales2015.csv,\n",
    "\n",
    "    RDEQISales2016.csv,\n",
    "\n",
    "    RDEQISales2017.csv,\n",
    "\n",
    "    RDEQISales2018.csv\n",
    "\n",
    "\n",
    "\n",
    "3.\n",
    "\n",
    "Plan:\n",
    "\n",
    "    1\tdownload all of the sales reports from the Washoe County's website for years 2005 to 2022\n",
    "\n",
    "    2\tusing Python convert all of the reports to CSV file type\n",
    "\n",
    "    3\tusing python add a new column to the report to indicate the year of the transaction\n",
    "\n",
    "    4\tusing python combine all of the reports into one file\n",
    "\n",
    "    5\tcreate a new table within SQLite\n",
    "\n",
    "    6\tload the csv into the database\n",
    "\n",
    "    7\tanalyze the data using the columns within the reports\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Intro (2 mins)\n",
    "\n",
    "    Hello my name is Habum\n",
    "    I am an Information Technology professional with an extensive background in Go to Market applications, such as Salesforce, Outreach, ZoomInfo, Consensus, Linkedin Sales Navigator and many more.\n",
    "    My primary responsibility includes maintaining Customer Relationship Management database and its integration with other applications.\n",
    "    I am currently enrolled in Savvy Coders to further develop my analytical skills and transform my technical database expertise into a data analytics role.\n",
    "    At my most recent employment, one of the responsibilities I found most rewarding was performing a monthly analysis of our ticketing system.\n",
    "    Although there were limitations on the type of information the data can provide, It helped me be more inquisitive and to think systematically.\n",
    "    applying this new-found curiosity to my own personal life, I decided to do my capstone project on the current house market in Reno.\n",
    "    The single-family home prices in the United States have soared over the years and although there have been some improvements in the affordability of single-family homes, I wanted to see how much the price of single-family homes has changed over time in Reno. (edited) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '../Capstone/Dataset/CSV/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_excel(file_path, skiprows\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[39m# Write the modified DataFrame back to a CSV file\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m data\u001b[39m.\u001b[39;49mto_csv(csv_folder, index\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\habum\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:3772\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3761\u001b[0m df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, ABCDataFrame) \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_frame()\n\u001b[0;32m   3763\u001b[0m formatter \u001b[39m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3764\u001b[0m     frame\u001b[39m=\u001b[39mdf,\n\u001b[0;32m   3765\u001b[0m     header\u001b[39m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3769\u001b[0m     decimal\u001b[39m=\u001b[39mdecimal,\n\u001b[0;32m   3770\u001b[0m )\n\u001b[1;32m-> 3772\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[39m.\u001b[39;49mto_csv(\n\u001b[0;32m   3773\u001b[0m     path_or_buf,\n\u001b[0;32m   3774\u001b[0m     lineterminator\u001b[39m=\u001b[39;49mlineterminator,\n\u001b[0;32m   3775\u001b[0m     sep\u001b[39m=\u001b[39;49msep,\n\u001b[0;32m   3776\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[0;32m   3777\u001b[0m     errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m   3778\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[0;32m   3779\u001b[0m     quoting\u001b[39m=\u001b[39;49mquoting,\n\u001b[0;32m   3780\u001b[0m     columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[0;32m   3781\u001b[0m     index_label\u001b[39m=\u001b[39;49mindex_label,\n\u001b[0;32m   3782\u001b[0m     mode\u001b[39m=\u001b[39;49mmode,\n\u001b[0;32m   3783\u001b[0m     chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[0;32m   3784\u001b[0m     quotechar\u001b[39m=\u001b[39;49mquotechar,\n\u001b[0;32m   3785\u001b[0m     date_format\u001b[39m=\u001b[39;49mdate_format,\n\u001b[0;32m   3786\u001b[0m     doublequote\u001b[39m=\u001b[39;49mdoublequote,\n\u001b[0;32m   3787\u001b[0m     escapechar\u001b[39m=\u001b[39;49mescapechar,\n\u001b[0;32m   3788\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[0;32m   3789\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\habum\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1186\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1165\u001b[0m     created_buffer \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1167\u001b[0m csv_formatter \u001b[39m=\u001b[39m CSVFormatter(\n\u001b[0;32m   1168\u001b[0m     path_or_buf\u001b[39m=\u001b[39mpath_or_buf,\n\u001b[0;32m   1169\u001b[0m     lineterminator\u001b[39m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1184\u001b[0m     formatter\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfmt,\n\u001b[0;32m   1185\u001b[0m )\n\u001b[1;32m-> 1186\u001b[0m csv_formatter\u001b[39m.\u001b[39;49msave()\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1189\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32mc:\\Users\\habum\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:240\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    237\u001b[0m \u001b[39mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[39m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 240\u001b[0m \u001b[39mwith\u001b[39;00m get_handle(\n\u001b[0;32m    241\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfilepath_or_buffer,\n\u001b[0;32m    242\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    243\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    244\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merrors,\n\u001b[0;32m    245\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompression,\n\u001b[0;32m    246\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstorage_options,\n\u001b[0;32m    247\u001b[0m ) \u001b[39mas\u001b[39;00m handles:\n\u001b[0;32m    248\u001b[0m     \u001b[39m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    249\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwriter \u001b[39m=\u001b[39m csvlib\u001b[39m.\u001b[39mwriter(\n\u001b[0;32m    250\u001b[0m         handles\u001b[39m.\u001b[39mhandle,\n\u001b[0;32m    251\u001b[0m         lineterminator\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    256\u001b[0m         quotechar\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquotechar,\n\u001b[0;32m    257\u001b[0m     )\n\u001b[0;32m    259\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save()\n",
      "File \u001b[1;32mc:\\Users\\habum\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[39m.\u001b[39mmode,\n\u001b[0;32m    862\u001b[0m             encoding\u001b[39m=\u001b[39mioargs\u001b[39m.\u001b[39mencoding,\n\u001b[0;32m    863\u001b[0m             errors\u001b[39m=\u001b[39merrors,\n\u001b[0;32m    864\u001b[0m             newline\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '../Capstone/Dataset/CSV/'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Directory containing your Excel files\n",
    "xlsx_folder = './Dataset/'\n",
    "csv_folder = './Dataset/CSV/'\n",
    "\n",
    "# Read the Excel file\n",
    "data = pd.read_excel('path/to/your/file.xlsx')\n",
    "\n",
    "# Print the header\n",
    "print(data)\n",
    "\n",
    "\n",
    "# Iterate over each file in the directory\n",
    "for filename in os.listdir(xlsx_folder):\n",
    "    if filename.endswith('.xlsx'):\n",
    "        # Construct the file path\n",
    "        file_path = os.path.join(xlsx_folder, filename)\n",
    "        csv_path = os.path.join(csv_folder, os.path.splitext(filename)[0] + '.csv')\n",
    "        \n",
    "        # Read the Excel file and skip the first row\n",
    "        data = pd.read_excel(file_path, skiprows=1)\n",
    "        \n",
    "        # Write the modified DataFrame back to a CSV file\n",
    "        data.to_csv(csv_folder, index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
